{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0_hy8SyAqYJ",
        "outputId": "e3acb572-5698-4e0b-f50c-218abf82a0ba"
      },
      "outputs": [],
      "source": [
        "if 'google.colab' in str(get_ipython()):\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sREC-whVAa4B",
        "outputId": "df636c01-604c-4694-82cb-af77f3103fd6"
      },
      "outputs": [],
      "source": [
        "!pip install bert_score datasets rouge_score evaluate transformers wandb accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVl4Mg4MBP07",
        "outputId": "b49481d3-b991-451b-fb77-cb419f0c11c9"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/Myashka/CQA_RLHF.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eG0pB6GjCxWD"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import yaml\n",
        "assert os.environ['COLAB_TPU_ADDR'], 'Make sure to select TPU from Edit > Notebook settings > Hardware accelerator'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gndBwr-DTYx",
        "outputId": "016b7b53-32b5-4afc-bb75-bad28df25b27"
      },
      "outputs": [],
      "source": [
        "!pip install cloud-tpu-client==0.10 torch==1.13.0 https://storage.googleapis.com/tpu-pytorch/wheels/colab/torch_xla-1.13-cp38-cp38-linux_x86_64.whl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGGiSFWCG65_",
        "outputId": "ef0405b1-6fef-43c4-a78f-4a7560cdf77a"
      },
      "outputs": [],
      "source": [
        "!accelerate config default --mixed_precision bf16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLY2R4JcHPti",
        "outputId": "d96a38eb-a282-425f-f67b-e01e4a2e8604"
      },
      "outputs": [],
      "source": [
        "!accelerate env"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer_config = dict(\n",
        "    model_name = 'EleutherAI/gpt-neo-125M',\n",
        "    seed = 42,\n",
        "    batch_size = 16,\n",
        "    max_length = 512,\n",
        "    learning_rate = 5e-5,\n",
        "    n_epoches = 3,\n",
        "    eval_every = 1000,\n",
        "    warmup_steps = 100,\n",
        "    wandb_kwargs = dict(\n",
        "        entity = 'myashka',\n",
        "        job_type = 'train',\n",
        "        group = 'sft'\n",
        "    ),\n",
        "    TPU = True,\n",
        "    gradient_accumulation_steps = 1,\n",
        "    freeze = True,\n",
        "    use_cache = False,\n",
        "    wandb_api = 'text'\n",
        ")\n",
        "\n",
        "with open('trainer_config.yaml', 'w') as outfile:\n",
        "    yaml.dump(trainer_config, outfile, default_flow_style=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ds_config = {\n",
        "    \"bf16\": {\"enabled\": True},\n",
        "    \"zero_optimization\": {\n",
        "        \"stage\": 3,\n",
        "        \"stage3_gather_16bit_weights_on_model_save\": False,\n",
        "        \"offload_optimizer\": {\"device\": None},\n",
        "        \"offload_param\": {\"device\": None},\n",
        "    },\n",
        "    \"gradient_clipping\": 1.0,\n",
        "    \"train_batch_size\": \"auto\",\n",
        "    \"train_micro_batch_size_per_gpu\": \"auto\",\n",
        "    \"gradient_accumulation_steps\": 1,\n",
        "    \"steps_per_print\": 2000000,\n",
        "}\n",
        "\n",
        "with open('ds-config.json', 'w') as f:\n",
        "    json.dump(ds_config, f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "accelerate_config = dict(\n",
        "    compute_environment = 'LOCAL_MACHINE',\n",
        "    deepspeed_config = dict(\n",
        "        deepspeed_config_file = 'c',\n",
        "        zero3_init_flag = True\n",
        "    ),\n",
        "    distributed_type = 'DEEPSPEED',\n",
        "    fsdp_config = dict(),\n",
        "    machine_rank = 0,\n",
        "    main_process_ip = None,\n",
        "    main_process_port = None,\n",
        "    main_training_function = 'main',\n",
        "    mixed_precision = 'bf16',\n",
        "    num_machines = 1,\n",
        "    num_processes = 8,\n",
        "    use_cpu = False\n",
        "\n",
        ")\n",
        "\n",
        "with open('accelerate_config.yaml', 'w') as outfile:\n",
        "    yaml.dump(accelerate_config, outfile, default_flow_style=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!mv accelerate_config.yaml "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H7ndLaUrIA7Q"
      },
      "outputs": [],
      "source": [
        "mixed_precision = 'bf16'\n",
        "output_dir = r'/content/drive/MyDrive/Diploma/Checkpoints'\n",
        "data_path = r'/content/drive/MyDrive/Diploma/data/1.0-data-div-ans-sep-test.json'\n",
        "\n",
        "num_processes = '8'\n",
        "config_file = r'/content/CQA_RLHF/sft/accelerate/config.yaml'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-ScZqrxHe8K",
        "outputId": "1d7a5e01-8600-4cbb-e2be-df07dc6d36f8"
      },
      "outputs": [],
      "source": [
        "!accelerate launch --tpu --downcast_bf16 --mixed_precision $mixed_precision /content/CQA_RLHF/sft/accelerate/train_accelerate.py --mixed_precision $mixed_precision --output_dir $output_dir --data_path $data_path --config_file $config_file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "veWhsK09I31e"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

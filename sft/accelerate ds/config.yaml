model_name: EleutherAI/gpt-neo-125M
seed: 42
batch_size: 8
max_length: 512
learning_rate: 5.e-5
n_epoches: 5
eval_every: 500
warmup_steps: 100
wandb_kwargs: {'entity': 'myashka', 'job_type': 'train', 'group': 'sft'}
TPU: True
gradient_accumulation_steps: 1
freeze: True
use_cache: False
wandb_api: text
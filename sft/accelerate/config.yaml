model_name: EleutherAI/gpt-neo-125M
seed: 42
batch_size: 8
max_length: 512
learning_rate: 2.e-5
max_steps: 195000
eval_every: 500
warmup_steps: 100
wandb_kwargs: {entity: 'myashka', job_type: 'train', group: 'sft'}
TPU: True
gradient_accumulation_steps: 1
freeze: True
use_cache: False
wandb_api: text
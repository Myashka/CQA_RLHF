model_name : EleutherAI/gpt-neo-125M
seed: 42
batch_size: 8
max_legth: 512
learning_rate": 2e-5
max_steps": 195000
eval_every": 500
warmup_steps": 100
wandb_kwargs": {entity: myashka, job_type: train, group: sft}
TPU: False
gradient_accumulation_steps": 1
wandb_api": "text"
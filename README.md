# CQA_RLHF

## Descpription

This GitHub repository is a collection of code and resources that correspond to CQA (Closed-Question Answering) and RLHF (Reinforcement Learning from Human Feedback) methods dedicated to the diploma work at ITMO University. The main focus of this repository is on fine-tuning the GPT-Neo model for CQA tasks.

Repository Structure:
The repository is organized into several directories to make it easy for users to navigate and find the relevant code and resources. The directories include:

data: This directory contains the data used for training and testing the CQA model.

notebooks: This directory contains Jupyter notebooks that explain the CQA and RLHF methods and demonstrate how to use the code.

sft: This directory contains the fine-tuning part of the GPT-Neo model. This is the most important directory for users who want to fine-tune the model on their own data.
